{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcQv3PZ4hLCb",
        "outputId": "52745d25-c480-4459-8d52-f98bbd175dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ],
      "source": [
        "pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhdI0Tn7hfcw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from memory_profiler import memory_usage\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "import psutil\n",
        "# import resource\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZkpKckOhhRz",
        "outputId": "495df61d-8ae5-4be3-d41e-272b9d87adce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab-Notebooks/Anomaly-Detection/CSV\n",
            "found True\n"
          ]
        }
      ],
      "source": [
        "# Define the image size\n",
        "import os\n",
        "IMG_SIZE = 50\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab-Notebooks/Anomaly-Detection/CSV\n",
        "\n",
        "# train_df = pd.read_csv('./train_final_index.csv')\n",
        "# test_df = pd.read_csv('./test_final_index.csv')\n",
        "# test_df = pd.read_csv('./val_final_index.csv')\n",
        "train_df = pd.read_csv('./train_feature_index.csv')\n",
        "# test_df = pd.read_csv('./test_feature_index.csv')\n",
        "# test_df = pd.read_csv('./val_feature_index.csv')\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab-Notebooks/Anomaly-Detection/fiveTwelve\"\n",
        "print(\"found\", os.path.exists(path=path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nTazSelhmwP"
      },
      "outputs": [],
      "source": [
        "X_train = train_df.drop(columns=[\"label\", \"path\"])\n",
        "y_train = train_df[\"label\"]\n",
        "\n",
        "X_test = train_df.drop(columns=[\"label\", \"path\"])\n",
        "y_test = train_df[\"label\"]\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image / 255.0\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPsh0wfGhotE",
        "outputId": "24b89240-9615-4662-af9c-83efbe54eb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process psutil.Process(pid=650, name='python3', status='running', started='12:53:43') before Memory 607.3515625\n"
          ]
        }
      ],
      "source": [
        "#Remove the memory code after testing\n",
        "# Sample 1\n",
        "process = psutil.Process()\n",
        "before_memory = process.memory_info().rss / 1024 / 1024  # Convert to MB\n",
        "print(\"process\", process, \"before Memory\", before_memory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8xikp3Ahr-n",
        "outputId": "f2c5d1ec-01ee-4172-a544-29e3622c3acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_neighbors': 6}\n",
            "Best Score: 0.9788868827096591\n",
            "{'n_neighbors': 6}\n"
          ]
        }
      ],
      "source": [
        "#KNN\n",
        "X_train_reorder = np.random.permutation(X_train)\n",
        "knn = KNeighborsClassifier()\n",
        "params_knn = {\"n_neighbors\": np.arange(1, 25)}\n",
        "knn_gs = GridSearchCV(knn, params_knn, cv=10)\n",
        "knn_gs.fit(X_train, y_train)\n",
        "knn_gs.fit(X_train_reorder, y_train)\n",
        "\n",
        "best_params = knn_gs.best_params_\n",
        "best_score = knn_gs.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "used_algorithm = knn.algorithm\n",
        "\n",
        "knn_best = knn_gs.best_estimator_\n",
        "print(knn_gs.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nne__19MhuE_",
        "outputId": "eec77d76-67fb-4dc1-b9e6-dfd41cba6bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 50}\n",
            "Best Parameters: {'n_estimators': 50}\n",
            "Best Score: 0.9788653634499218\n"
          ]
        }
      ],
      "source": [
        "#Random Forest\n",
        "X_train_reorder = np.random.permutation(X_train)\n",
        "rf = RandomForestClassifier()\n",
        "params_rf = {\"n_estimators\": [50, 100, 200]}\n",
        "rf_gs = GridSearchCV(rf, params_rf, cv=10)\n",
        "rf_gs.fit(X_train, y_train)\n",
        "rf_gs.fit(X_train_reorder, y_train)\n",
        "\n",
        "\n",
        "rf_best = rf_gs.best_estimator_\n",
        "print(rf_gs.best_params_)\n",
        "rf_best_params = rf_gs.best_params_\n",
        "rf_best_score = rf_gs.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", rf_best_params)\n",
        "print(\"Best Score:\", rf_best_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxzpz7gLhwr7",
        "outputId": "60aea18b-9d26-4b25-c25b-11cfdb53f576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knn: 0.9788868801652892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf: 0.959323347107438\n",
            "Ens_best 0.9856017561983471\n",
            "confusion_matrix [[45483     0]\n",
            " [  669   312]]\n",
            "F1 Score: 0.7376489520045546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "print(\"knn: {}\".format(knn_best.score(X_test, y_test)))\n",
        "print(\"rf: {}\".format(rf_best.score(X_test, y_test)))\n",
        "\n",
        "estimators=[(\"knn\", knn_best), (\"rf\", rf_best)]\n",
        "ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "# ensemble = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "ens_best = ensemble.score(X_test, y_test)\n",
        "\n",
        "print(\"Ens_best\", ens_best)\n",
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"confusion_matrix\", cm)\n",
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "y_pred_labels = y_pred\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_labels, average='macro')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "ens_labels = ensemble.predict(X_test)\n",
        "\n",
        "score1 = knn_best.score(X_test, y_test)\n",
        "score2 = rf_best.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybv-VnWohzX-",
        "outputId": "d0323510-3092-4819-8793-697bc4049bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:             radius    texture     perimeter    area    smoothness  \\\n",
            "40320   217.524111  76.482487   1366.744299   75391  2.477736e+01   \n",
            "4235   1569.689986  44.668763   9862.653060       2  4.863596e+07   \n",
            "8723   1523.988731  46.390498   9575.503602   87264  1.050723e+03   \n",
            "15482  1324.938432  40.284425   8324.833688   99147  6.989910e+02   \n",
            "15541   221.983998  71.378539   1394.766594  101983  1.907547e+01   \n",
            "...            ...        ...           ...     ...           ...   \n",
            "11284  2440.103466  36.714284  15331.622250  102674  2.289369e+03   \n",
            "44732  1165.958112  48.651823   7325.930876   94176  5.698826e+02   \n",
            "38158  1835.768665  44.191267  11534.474700   96081  1.384708e+03   \n",
            "860     209.415609  76.584200   1315.797077  130988  1.321741e+01   \n",
            "15795  1970.412914  55.397512  12380.469470   93826  1.633620e+03   \n",
            "\n",
            "        compactness  concavity  concave_points   symmetry  fractal_dimension  \\\n",
            "40320  2.477736e+01       4801          -79680  39.101562           0.952986   \n",
            "4235   4.863596e+07          0              -1  47.783203           0.175293   \n",
            "8723   1.050723e+03        971          -87723  50.828125           0.758578   \n",
            "15482  6.989910e+02        876          -99511  49.094727           0.777411   \n",
            "15541  1.907547e+01       2404         -103875  52.190430           0.971177   \n",
            "...             ...        ...             ...        ...                ...   \n",
            "11284  2.289369e+03        460         -102622  51.465820           0.729966   \n",
            "44732  5.698826e+02        238          -93902  45.874023           0.785688   \n",
            "38158  1.384708e+03        268          -95837  52.416016           0.748628   \n",
            "860    1.321741e+01         84         -130560  61.527344           0.996484   \n",
            "15795  1.633620e+03       3339          -96653  51.500000           0.741745   \n",
            "\n",
            "                                                    path  \n",
            "40320  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "4235   /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "8723   /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "15482  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "15541  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "...                                                  ...  \n",
            "11284  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "44732  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "38158  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "860    /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "15795  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "\n",
            "[37171 rows x 11 columns]\n",
            "X_test:             radius    texture     perimeter    area   smoothness  compactness  \\\n",
            "29003  1166.343287  44.309282   7328.351006   90326   594.565557   594.565557   \n",
            "7667   1644.767817  48.948936  10334.380980   96860  1102.616460  1102.616460   \n",
            "21871   245.391085  72.784747   1541.837662   93226    25.500004    25.500004   \n",
            "37472  2272.458032  37.948481  14278.274920   98471  2070.346951  2070.346951   \n",
            "15998  2148.143605  41.844968  13497.184340   91623  1988.299717  1988.299717   \n",
            "...            ...        ...           ...     ...          ...          ...   \n",
            "16629  1447.551859  48.009225   9095.236575   75752  1092.028308  1092.028308   \n",
            "23268  1290.697745  52.986592   8109.693106   95134   691.310386   691.310386   \n",
            "27695   222.305052  71.598249   1396.783838  106448    18.328246    18.328246   \n",
            "9920   1659.346864  44.515576  10425.983830   91360  1189.811065  1189.811065   \n",
            "43842   216.093491  66.042010   1357.755447   94498    19.508348    19.508348   \n",
            "\n",
            "       concavity  concave_points   symmetry  fractal_dimension  \\\n",
            "29003      12986         -102800  51.988281           0.783313   \n",
            "7667         442          -96790  49.180664           0.757963   \n",
            "21871       6426          -99140  50.861328           0.951799   \n",
            "37472        467          -98426  52.174805           0.733212   \n",
            "15998       7482          -98593  49.273438           0.733760   \n",
            "...          ...             ...        ...                ...   \n",
            "16629      13205          -88445  51.735352           0.755100   \n",
            "23268       7656         -102278  54.499023           0.777378   \n",
            "27695       1877         -107813  56.106445           0.973942   \n",
            "9920         672          -91520  44.979492           0.754080   \n",
            "43842       1419          -95405  46.802734           0.969515   \n",
            "\n",
            "                                                    path  \n",
            "29003  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "7667   /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "21871  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "37472  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "15998  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "...                                                  ...  \n",
            "16629  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "23268  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "27695  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "9920   /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "43842  /content/drive/MyDrive/Colab-Notebooks/Anomaly...  \n",
            "\n",
            "[9293 rows x 11 columns]\n",
            "y_train: 40320    0\n",
            "4235     0\n",
            "8723     0\n",
            "15482    0\n",
            "15541    0\n",
            "        ..\n",
            "11284    0\n",
            "44732    0\n",
            "38158    0\n",
            "860      0\n",
            "15795    0\n",
            "Name: label, Length: 37171, dtype: int64\n",
            "y_test: 29003    0\n",
            "7667     0\n",
            "21871    0\n",
            "37472    0\n",
            "15998    0\n",
            "        ..\n",
            "16629    0\n",
            "23268    0\n",
            "27695    0\n",
            "9920     0\n",
            "43842    0\n",
            "Name: label, Length: 9293, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def image_generator(X, y, batch_size=32):\n",
        "    num_samples = len(X)\n",
        "    indices = np.arange(num_samples)\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "        batch_indices = []\n",
        "        for start in range(0, num_samples, batch_size):\n",
        "            end = min(start + batch_size, num_samples)\n",
        "            batch_indices.extend(indices[start:end])\n",
        "\n",
        "            if len(batch_indices) == batch_size:\n",
        "                batch_X = np.zeros((batch_size, 224, 224, 3))\n",
        "                batch_y = np.zeros((batch_size,))  # Use num_classes from your problem\n",
        "\n",
        "                for i, idx in enumerate(batch_indices):\n",
        "                    if idx >= num_samples:\n",
        "                        continue  # Skip this sample\n",
        "\n",
        "                    if \"path\" not in X.iloc[idx]:\n",
        "                        continue  # Skip this sample if 'path' key is missing\n",
        "\n",
        "                    path = X.iloc[idx][\"path\"]\n",
        "                    image = load_and_preprocess_image(path)\n",
        "                    if image is None:\n",
        "                        continue  # Skip this sample\n",
        "\n",
        "                    batch_X[i] = image\n",
        "                    batch_y[i] = y.iloc[idx]\n",
        "\n",
        "                yield batch_X, batch_y\n",
        "                batch_indices = []\n",
        "\n",
        "        # If there are remaining samples that don't form a full batch, process them as well\n",
        "        if batch_indices:\n",
        "            batch_X = np.zeros((len(batch_indices), 224, 224, 3))\n",
        "            batch_y = np.zeros((len(batch_indices), 10))  # Use num_classes from your problem\n",
        "            for i, idx in enumerate(batch_indices):\n",
        "                if idx >= num_samples:\n",
        "                    continue  # Skip this sample\n",
        "\n",
        "                if \"path\" not in X.iloc[idx]:\n",
        "                    continue  # Skip this sample if 'path' key is missing\n",
        "\n",
        "                path = X.iloc[idx][\"path\"]\n",
        "                image = load_and_preprocess_image(path)\n",
        "                if image is None:\n",
        "                    continue  # Skip this sample\n",
        "\n",
        "                batch_X[i] = image\n",
        "                batch_y[i] = y.iloc[idx]\n",
        "\n",
        "            yield batch_X, batch_y\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = cv2.imread(path)\n",
        "    if(image is not None):\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image = cv2.resize(image, (224, 224))\n",
        "      image = image / 255.0\n",
        "    return image\n",
        "\n",
        "# X_train = train_df.drop(columns=[\"label\", \"path_id\"])\n",
        "# y_train = train_df[\"label\"]\n",
        "\n",
        "# X_test = test_df.drop(columns=[\"label\", \"path_id\"])\n",
        "# y_test = test_df[\"label\"]\n",
        "X = train_df.drop(columns=[\"label\", \"path_id\"])\n",
        "y = train_df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"y_train:\", y_train)\n",
        "print(\"y_test:\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yihyi6cqh3Qv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dropout\n",
        "def run_code():\n",
        "    base_model = EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    print(\"***********Model Complied*************\")\n",
        "    # print(\"X_test\", X_test, \"y_test\", y_test)\n",
        "    train_generator = image_generator(X_train, y_train, 500)\n",
        "    test_generator = image_generator(X_test, y_test, 500)\n",
        "    # print(\"test_generator\",test_generator)\n",
        "\n",
        "    X_train_processed, y_train_processed = next(train_generator)\n",
        "    X_test_processed, y_test_processed = next(test_generator)\n",
        "    # print(\"X_test_processed\", len(X_test_processed), \"y_test_processed\", len(y_test_processed))\n",
        "\n",
        "    epochs = 10\n",
        "    accuracy_history = []\n",
        "    loss_history = []\n",
        "    val_loss_history=[]\n",
        "    val_accuracy_history=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        history = model.fit(X_train_processed, y_train_processed, epochs=1, validation_data=(X_test_processed, y_test_processed))\n",
        "        batch_size = 32\n",
        "        training_accuracy = history.history['accuracy'][0]\n",
        "        training_loss = history.history['loss'][0]\n",
        "        val_accuracy=history.history['val_accuracy'][0]\n",
        "        val_loss=history.history['val_loss'][0]\n",
        "\n",
        "        # Append the accuracy and loss lists for all epochs to history\n",
        "        accuracy_history.append(training_accuracy)\n",
        "        loss_history.append(training_loss)\n",
        "        val_accuracy_history.append(val_accuracy)\n",
        "        val_loss_history.append(val_loss)\n",
        "\n",
        "    # model.fit(X_train_processed, y_train_processed, validation_data=(X_test_processed, y_test_processed), epochs=10)\n",
        "\n",
        "    print(\"accuracy_history:\", accuracy_history)\n",
        "    print(\"loss_history:\", loss_history)\n",
        "    print(\"***********Completed*************\")\n",
        "    print(\"val_loss_history:\", val_loss_history)\n",
        "    print(\"val_accuracy_history:\", val_accuracy_history)\n",
        "    test_loss, test_acc = model.evaluate(X_test_processed, y_test_processed)\n",
        "    print(\"Test Loss:\",test_loss, \"Test accuracy:\", test_acc)\n",
        "    print(\"***********Completed*************\")\n",
        "    # Assuming y_test_processed contains binary labels (0 and 1)\n",
        "    y_pred = model.predict(X_test_processed)\n",
        "    y_pred_labels = y_pred.argmax(axis=1) # Convert probabilities to binary labels\n",
        "\n",
        "    # print(\"y_test_processed\", y_test_processed , \"y_pred_labels\", y_pred_labels, \"X_test_processed\", X_test_processed)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test_processed, y_pred_labels)\n",
        "    print(report)\n",
        "    print(\"************************************\")\n",
        "    # Convert the data type of y_test_processed to integer\n",
        "    y_test_processed = y_test_processed.astype(int)\n",
        "\n",
        "    # Get predicted labels from the model\n",
        "    y_pred = model.predict(X_test_processed)\n",
        "    print(\"y_pred\", y_pred, y_test_processed)\n",
        "    y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(y_test_processed, y_pred_labels)\n",
        "    print(\"Confusion Matrix:\", cm)\n",
        "    print(\"************************************\")\n",
        "    # Calculate the F1 score\n",
        "    f1 = f1_score(y_test_processed, y_pred_labels, average='macro')\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"************************************\")\n",
        "\n",
        "    #Accuracy Graph\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    # Plot training accuracy\n",
        "    plt.plot(range(1, epochs + 1), np.exp(accuracy_history), linestyle='-', label='Training Accuracy')\n",
        "    # Plot testing accuracy\n",
        "    plt.plot(range(1, epochs + 1), np.exp(val_accuracy_history), linestyle='-', label='Testing Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.xticks(np.arange(1, epochs + 1))\n",
        "    plt.ylim(0, np.exp(1))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    #Loss Graph\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    # Plot training loss\n",
        "    plt.plot(range(1, epochs + 1), np.exp(loss_history), linestyle='-', label='Training Loss')\n",
        "    # Plot testing loss\n",
        "    plt.plot(range(1, epochs + 1), np.exp(val_loss_history), linestyle='-', label='Testing Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.xticks(np.arange(1, epochs + 1))\n",
        "    plt.ylim(0, np.exp(1))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test_processed, y_pred[:, 1])\n",
        "\n",
        "    # Calculate area under the precision-recall curve (AUC-PR)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    print(\"Precision-Recall curve: AUC=\", auc_pr)\n",
        "\n",
        "    # Plot precision-recall curve\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (AUC = %0.2f)' % auc_pr)\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc='lower left')\n",
        "    plt.show()\n",
        "    return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "9XWoTSbFlmXB",
        "outputId": "ed6fc26e-54ef-42e9-9ca2-1f3c257800b0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3ba18a2849f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mafter_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m  \u001b[0;31m# Convert to MB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmemory_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter_memory\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbefore_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Memory usage:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0e5f2af9b5d6>\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientNetB7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EfficientNetB7' is not defined"
          ]
        }
      ],
      "source": [
        "run_code()\n",
        "\n",
        "after_memory = process.memory_info().rss / 1024 / 1024  # Convert to MB\n",
        "memory_usage = after_memory - before_memory\n",
        "print(\"Memory usage:\", memory_usage, \"MB\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}