{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.draw import ellipse_perimeter, circle_perimeter\n",
        "\n",
        "def extract_circular_points(regions):\n",
        "    circular_points = []\n",
        "\n",
        "    for region in regions:\n",
        "        # Check circularity of the region\n",
        "        circularity = region.perimeter ** 2 / (4 * np.pi * region.area)\n",
        "\n",
        "        # Define a circularity threshold (adjust as needed)\n",
        "        circularity_threshold = 0.8\n",
        "\n",
        "        if circularity > circularity_threshold:\n",
        "            # Get the centroid coordinates\n",
        "            centroid_row, centroid_col = region.centroid\n",
        "\n",
        "            # Generate more results for the circular point\n",
        "            additional_results = generate_additional_results(centroid_row, centroid_col)\n",
        "\n",
        "            # Append the circular point and additional results to the list\n",
        "            circular_points.append({\n",
        "                'centroid_row': centroid_row,\n",
        "                'centroid_col': centroid_col,\n",
        "                'additional_results': additional_results\n",
        "            })\n",
        "\n",
        "    return circular_points\n",
        "\n",
        "def generate_additional_results(row, col):\n",
        "    # Generate additional results for the circular point, e.g., extract pixel values or statistics\n",
        "    additional_results = {}\n",
        "\n",
        "    # Example: Get the pixel values along the circular perimeter\n",
        "    min_radius = 1\n",
        "    max_radius = 15\n",
        "\n",
        "    # Generate circular and elliptical perimeters\n",
        "    perimeters = []\n",
        "    for radius in range(min_radius, max_radius+1):\n",
        "        circle_perimeter_row, circle_perimeter_col = circle_perimeter(int(row), int(col), radius=radius)\n",
        "        ellipse_perimeter_row, ellipse_perimeter_col = ellipse_perimeter(int(row), int(col), radius, int(radius*1.5))\n",
        "        perimeters.append((circle_perimeter_row, circle_perimeter_col))\n",
        "        perimeters.append((ellipse_perimeter_row, ellipse_perimeter_col))\n",
        "\n",
        "    # Extract pixel values for each perimeter\n",
        "    pixel_values = []\n",
        "    for perimeter_row, perimeter_col in perimeters:\n",
        "        pixel_values.append((perimeter_row, perimeter_col))\n",
        "\n",
        "    additional_results['perimeter_pixel_values'] = pixel_values\n",
        "\n",
        "    return additional_results"
      ],
      "metadata": {
        "id": "DfRack13V6bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGN2CBGeRbPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io, color, filters, measure\n",
        "import scipy.ndimage as ndi\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed\n",
        "import matplotlib.pyplot as plt\n",
        "# from extract_circular_points import extract_circular_points\n",
        "\n",
        "# Function to perform image segmentation\n",
        "def perform_segmentation(image_path):\n",
        "    # Load the image and convert it to grayscale\n",
        "    img = io.imread(image_path)\n",
        "    img_gray = color.rgb2gray(img)\n",
        "\n",
        "    # Apply histogram equalization to enhance contrast\n",
        "    img_gray = exposure.equalize_hist(img_gray)\n",
        "\n",
        "    # Compute the distance transform\n",
        "    distance = ndi.distance_transform_edt(img_gray)\n",
        "\n",
        "    # Calculate the threshold using Otsu's method\n",
        "    threshold = filters.threshold_otsu(img_gray)\n",
        "\n",
        "    # Find peaks in the distance map\n",
        "    markers = peak_local_max(distance, min_distance=10, labels=img_gray > threshold)\n",
        "\n",
        "    # Resize markers to the same shape as the mask\n",
        "    markers = np.resize(markers, img_gray.shape)\n",
        "\n",
        "    # Perform watershed segmentation\n",
        "    labeled_image = watershed(-distance, markers, mask=img_gray)\n",
        "\n",
        "    return labeled_image\n",
        "\n",
        "# Function to extract features from segmented regions\n",
        "def extract_features_from_segmentation(labeled_image, img_gray, label, filepath):\n",
        "    # Calculate the features from each segmented region\n",
        "    regions = measure.regionprops(labeled_image, intensity_image=img_gray)\n",
        "\n",
        "    circular_points = extract_circular_points(regions)\n",
        "\n",
        "    # Create subplots for displaying images side by side\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    # Display the grayscale image without the red color\n",
        "    axs[0].imshow(img_gray, cmap='gray')\n",
        "    axs[0].set_title('Grayscale Image')\n",
        "\n",
        "    # Display the original image with circular points\n",
        "    axs[1].imshow(img_gray)\n",
        "    axs[1].set_title('Original Image')\n",
        "\n",
        "    # Plot the circular points and perimeters\n",
        "    for circular_point in circular_points:\n",
        "        centroid_row = circular_point['centroid_row']\n",
        "        centroid_col = circular_point['centroid_col']\n",
        "        additional_results = circular_point['additional_results']\n",
        "\n",
        "        # Plot the centroid point as a dot\n",
        "        axs[1].plot(centroid_col, centroid_row, 'ro', markersize=5)\n",
        "\n",
        "        # Plot the circular and elliptical perimeters\n",
        "        for perimeter_row, perimeter_col in additional_results['perimeter_pixel_values']:\n",
        "            axs[1].plot(perimeter_col, perimeter_row, 'r-', linewidth=1)\n",
        "\n",
        "    # Adjust spacing between subplots\n",
        "    # plt.tight_layout()\n",
        "\n",
        "    # # Show the plot\n",
        "    # plt.show()\n",
        "\n",
        "    # Access the circular points and additional results\n",
        "    for circular_point in circular_points:\n",
        "        centroid_row = circular_point['centroid_row']\n",
        "        centroid_col = circular_point['centroid_col']\n",
        "        # additional_results = circular_point['additional_results']\n",
        "        # print(f\"Circular Point: Row={centroid_row}, Col={centroid_col}\")\n",
        "\n",
        "    features = []\n",
        "    concave_points_values = []\n",
        "    symmetry_values = []\n",
        "    fractal_dimension_values = []\n",
        "\n",
        "    count = 0\n",
        "    for i, region in enumerate(regions):\n",
        "        # print(\"region\", region, region.perimeter, region.area, region.convex_area, region.convex_image)\n",
        "        if region.area == 0 or region.perimeter == 0:\n",
        "            continue\n",
        "        radius = region.perimeter / (2.0 * np.pi)\n",
        "        texture = np.std(img_gray[region.slice])\n",
        "        perimeter = region.perimeter\n",
        "        area = region.area\n",
        "        smoothness = (perimeter ** 2) / area\n",
        "        compactness = (perimeter ** 2) / area\n",
        "        concavity = region.convex_area - area\n",
        "        concave_points = len(region.convex_image) - np.sum(region.convex_image)\n",
        "        IMG_SIZE = max(img_gray.shape)\n",
        "        symmetry = np.sum(np.abs(img_gray[region.slice] - np.flipud(img_gray[region.slice]))) / (IMG_SIZE ** 2)\n",
        "        fractal_dimension = np.log(4 * np.pi * area) / (2 * np.log(perimeter))\n",
        "\n",
        "        if concave_points != 0:\n",
        "            concave_points_values.append(concave_points)\n",
        "        if concave_points == 0:\n",
        "            concave_points = np.mean(concave_points_values)\n",
        "\n",
        "        if symmetry != 0:\n",
        "            symmetry_values.append(symmetry)\n",
        "        if symmetry == 0:\n",
        "            symmetry = np.mean(symmetry_values)\n",
        "\n",
        "        if fractal_dimension != 0:\n",
        "            fractal_dimension_values.append(fractal_dimension)\n",
        "        if fractal_dimension == 0:\n",
        "            fractal_dimension = np.mean(fractal_dimension_values)\n",
        "\n",
        "        count = count+1\n",
        "        feature = {\n",
        "            'radius': radius,\n",
        "            'texture': texture,\n",
        "            'perimeter': perimeter,\n",
        "            'area': area,\n",
        "            'smoothness': smoothness,\n",
        "            'compactness': compactness,\n",
        "            'concavity': concavity,\n",
        "            'concave_points': concave_points,\n",
        "            'symmetry': symmetry,\n",
        "            'fractal_dimension': fractal_dimension,\n",
        "            'label': label,\n",
        "            'path': filepath,\n",
        "            'path_id': count\n",
        "        }\n",
        "        print(\"feature\", feature)\n",
        "        # if(i==0):\n",
        "        #     print(\"labeled_image\", labeled_image, label, feature)\n",
        "        #     plt.imshow(labeled_image)\n",
        "        #     plt.axis('off')  # Turn off the axis labels\n",
        "        #     plt.show()\n",
        "        features.append(feature)\n",
        "    return features"
      ],
      "metadata": {
        "id": "RfAgqjZ1Vsvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hIA6HedBhz0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "from skimage import io, color\n",
        "# from segmentation import perform_segmentation, extract_features_from_segmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image size\n",
        "IMG_SIZE = 50\n",
        "\n",
        "TRAIN_DIR = '/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/Image_to_dataset/fiveTwelveSmall/train'\n",
        "# TRAIN_DIR = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/fiveTwelve/train')\n",
        "TEST_DIR = '/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/Image_to_dataset/fiveTwelveSmall/test'\n",
        "# TEST_DIR = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/fiveTwelve/test')\n",
        "VAL_DIR = '/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/Image_to_dataset/fiveTwelveSmall/val'\n",
        "# VAL_DIR = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/fiveTwelve/val')"
      ],
      "metadata": {
        "id": "Ws3lnv2pBpgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels for the two classes (normal and abnormal)\n",
        "CATEGORIES = ['false', 'true']\n",
        "\n",
        "# Function to read and preprocess images\n",
        "def read_and_preprocess_image(filepath):\n",
        "    # Read the image file\n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    # Resize the image to the desired size\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    # Flatten the image to a 1D array\n",
        "    img = img.flatten()\n",
        "    return img"
      ],
      "metadata": {
        "id": "2Vuh8WzuBtDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images and labels from a directory\n",
        "def load_data_from_folder(folder):\n",
        "    # Initialize the image and label lists\n",
        "    images = []\n",
        "    labels = []\n",
        "    features = []\n",
        "    folds = os.listdir(folder)\n",
        "    # Loop over the categories\n",
        "    for category in folds:\n",
        "        # Define the path to the category folder\n",
        "        path = os.path.join(folder, category)\n",
        "        # Loop over the image files in the category folder\n",
        "        for filename in os.listdir(path):\n",
        "            # Define the path to the image file\n",
        "            filepath = os.path.join(path, filename)\n",
        "            # Read and preprocess the image\n",
        "            img = read_and_preprocess_image(filepath)\n",
        "\n",
        "            # Load the grayscale image\n",
        "            # Append the image and label to the lists\n",
        "            label = 1\n",
        "            if \"false\" in category:\n",
        "                label = 0\n",
        "            labeled_image = perform_segmentation(filepath)\n",
        "            img_gray = color.rgb2gray(io.imread(filepath))\n",
        "\n",
        "            feature_array = extract_features_from_segmentation(labeled_image, img_gray, label, filepath)\n",
        "            # print(\"featire_array\", feature_array)\n",
        "            # feature = [item for sublist in feature_array for item in sublist]\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "            if(len(feature_array)>0):\n",
        "                features.append(feature_array[0])    # print(\"features\", len(features))\n",
        "    return images, labels, features\n",
        "\n",
        "# Load the train, test, and val data\n",
        "train_images, train_labels, train_feature = load_data_from_folder(TRAIN_DIR)\n",
        "test_images, test_labels, test_feature = load_data_from_folder(TEST_DIR)\n",
        "val_images, val_labels, val_feature = load_data_from_folder(VAL_DIR)\n",
        "\n",
        "# print(\"feature\",train_feature)\n",
        "\n",
        "# best_feature = max(train_feature, key=lambda x: x['area'])\n",
        "# print(\"best_feature\", best_feature)\n",
        "\n",
        "data = train_feature\n",
        "# Open a CSV file for writing\n",
        "with open('train_final1.csv', 'w', newline='') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "\n",
        "    print(\"data\", data[0])\n",
        "    # Write the header row\n",
        "    writer.writerow(data[0].keys())\n",
        "\n",
        "    # Write each row of data\n",
        "    for row in data:\n",
        "        writer.writerow(row.values())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "KA77HanRB2w9",
        "outputId": "36daea68-20fb-49d7-af33-b102d701c5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6a9d69b461a4>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Load the train, test, and val data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6a9d69b461a4>\u001b[0m in \u001b[0;36mload_data_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Loop over the categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Anomaly Detection/Image_to_dataset/fiveTwelveSmall/train'"
          ]
        }
      ]
    }
  ]
}